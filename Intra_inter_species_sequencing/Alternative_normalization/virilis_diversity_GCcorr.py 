#!/usr/bin/python
# virilis_diversity_GCcorr.py  

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import OrderedDict as odict

vir = pd.read_table('/Users/jullienflynn/Documents/AndyLab/Heterochromatin/PacBio_scripts/Revised_scripts/D_virilis_satellites_analysis/Intra_inter_species_sequencing/Alternative_normalization/Dvir_diversity.rep.compiled', index_col=0)
# remove total and N column:
vir = vir.drop(['total_bp'], axis=1)

def cleanup_line_names(df):
    split_names = df.index.str.split('.')
    new_index = []
    for sn in split_names:
        new_index.append(sn[0])
    df.index = new_index
    
def cleanup_kmer_names(df):
    kmer_names = df.columns.str.split('/')
    new_names = []
    for n in kmer_names:
        new_names.append(n[0])
    df.columns = new_names
    
def get_gc_content(dna):
    return (dna.count('C') + dna.count('G'))/len(dna)

# unit test:
assert np.isclose(get_gc_content('ACTAGCTAGTCGATCTATAATCGTAGTGCATGCTAGCTA'),
                 0.41025641)
                 
cleanup_line_names(vir)
cleanup_kmer_names(vir)
# reorder k-mers by GC content:
vir = vir.reindex_axis(sorted(vir.columns, key=get_gc_content), axis=1)

MIN_READS = 30000

import os
from collections import OrderedDict as odict
samples = odict()
gcbias_dir = '/Users/jullienflynn/Users/jullienflynn/Documents/AndyLab/Proposal/ThesisWork/Chapter1/Sequencing_diversity/noXY/'
for gcbias_file in os.listdir(gcbias_dir):
    sample_name_1 = gcbias_file.split('_')[0]
    sample_name_2 = gcbias_file.split('_')[1]
    sample_name_3 = gcbias_file.split('_')[2]
    sample_name = sample_name_1 + "_" + sample_name_2 + "_" + sample_name_3
    df = pd.read_table(gcbias_dir + gcbias_file, index_col=0)
    # Remove GC contents with less than MIN_READS overlapping reads:
    df = df.loc[df['Overlapping Reads'] > MIN_READS]
    samples[sample_name] = df

def get_avg_cov(df):
    return (df.sum()['Overlapping Reads'])/(df.sum()['Num. Positions'])
    
print('%10s\t%6s' % ('line', 'avg. cov'))
for sample in samples:
    print('%10s\t%2.3f'% (sample, get_avg_cov(samples[sample])))

def get_bins():
    bins = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 1.0]
    return bins

samples_binned = odict()
bins = get_bins()
for samplename in samples:
    sample = samples[samplename]
    grouped = sample.groupby(pd.cut(sample.index, bins, include_lowest=True))
    binned = grouped.mean()['Avg. Coverage']
    binned = binned.replace(np.nan, get_avg_cov(sample))
    samples_binned[samplename] = binned

def correct_counts(kmer_counts, correction_tables, method):
    kmers = kmer_counts.columns
    samples = kmer_counts.index
    corrected_counts = pd.DataFrame(index = samples, columns=kmers)
    for kmer in kmers:
        gc = get_gc_content(kmer)
        for sample in samples:
            sample_table = correction_tables[sample]
            corr = method(gc, sample_table)
            corrected_counts.loc[sample, kmer] = kmer_counts.loc[sample, kmer]/corr
    return corrected_counts.applymap(lambda x: int(round(x)))

# unit test:
def test_correct_counts():
    def dont_correct(*args):
        return 1
    corrected = correct_counts(vir.iloc[0:3,5:10],
                                                 samples, method=dont_correct)
    assert corrected.equals(vir.iloc[0:3,5:10])
test_correct_counts()


def match_binned_avg(gc, correction_table):
    cats = correction_table.index
    if gc == 0:
        cat = cats[0]
    for c in cats:
        c_min = float(c.split(',')[0][1:])
        c_max = float(c.split(',')[1][:-1])
        if (gc > c_min) & (gc <= c_max):
            cat = c
            break
    return correction_table.loc[cat]

corrected = correct_counts(vir, samples_binned, match_binned_avg)

corrected.to_csv('/Users/jullienflynn/Documents/AndyLab/Heterochromatin/PacBio_scripts/Revised_scripts/D_virilis_satellites_analysis/Intra_inter_species_sequencing/Alternative_normalization/virilis_group.GCcorr.maskednolow.noXYvir.csv')
